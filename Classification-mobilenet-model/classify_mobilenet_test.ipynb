{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b55cb372",
   "metadata": {},
   "source": [
    "# LIBRARIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b6e40083",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.preprocessing import image\n",
    "from keras.models import load_model\n",
    "import ast, os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d07b587",
   "metadata": {},
   "source": [
    "# LABELLING "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4ac0395",
   "metadata": {},
   "source": [
    "# ast - abstract syntax tree - analysis tool\n",
    "\n",
    "# literal_eval - identifying data type of the content in a file by traversing through the nodes of the tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "853de809",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: '100_new_back_down', 1: '100_new_back_up', 2: '100_new_front_down', 3: '100_new_front_up', 4: '100_old_back_down', 5: '100_old_back_up', 6: '100_old_front_down', 7: '100_old_front_up', 8: '10_new_back_down', 9: '10_new_back_up', 10: '10_new_front_down', 11: '10_new_front_up', 12: '10_old_back_down', 13: '10_old_back_up', 14: '10_old_front_down', 15: '10_old_front_up', 16: '2000_new_back_down', 17: '2000_new_back_up', 18: '2000_new_front_down', 19: '2000_new_front_up', 20: '200_new_back_down', 21: '200_new_back_up', 22: '200_new_front_down', 23: '200_new_front_up', 24: '20_new_back_down', 25: '20_new_back_up', 26: '20_new_front_down', 27: '20_new_front_up', 28: '20_old_back_down', 29: '20_old_back_up', 30: '20_old_front_down', 31: '20_old_front_up', 32: '500_new_back_down', 33: '500_new_back_up', 34: '500_new_front_down', 35: '500_new_front_up', 36: '50_new_back_down', 37: '50_new_back_up', 38: '50_new_front_down', 39: '50_new_front_up', 40: '50_old_back_down', 41: '50_old_back_up', 42: '50_old_front_down', 43: '50_old_front_up', 44: 'invalid'}\n"
     ]
    }
   ],
   "source": [
    "#loading model into model parameter\n",
    "model = load_model('currency_mobilenetmodel.h5')\n",
    "\n",
    "#opening currency classes text file\n",
    "f = open(\"mobilenet_currency_class_indices.txt\", \"r\")\n",
    "\n",
    "#reading the text file into labels parameter\n",
    "labels = f.read()\n",
    "\n",
    "#identifying data type of the content in a file by traversing through the nodes of the tree\n",
    "labels = ast.literal_eval(labels)\n",
    "#print(labels)\n",
    "#interchanging and printing the values as label:class instead of class:label\n",
    "final_labels = {v: k for k, v in labels.items()}\n",
    "print(final_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5afa886c",
   "metadata": {},
   "source": [
    "# PREDICTING IMAGE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89ab91c2",
   "metadata": {},
   "source": [
    "# load_img-loads image into PIL(Python Imaging Library) format-provides the python interpreter with image editing capabilities.\n",
    "\n",
    "# asarray-converts input to array-returns an array\n",
    "\n",
    "# np.expand_dims-expand shape of an array\n",
    "\n",
    "# result_dict[final_labels[key]] = result[0][key] - mapping every value of result array to the classes in final_label dictionary (final_labels[key]-gives values of respective keys from dictionary)\n",
    "\n",
    "# dict.items()-returns tuple of key value pairs\n",
    "\n",
    "# sorted() -used to sort dictionary\n",
    "\n",
    "# key - supports a inline function-here it returns item[1] as item which in this case probability values beside every class name({class-items[0]:prob-items[1]})\n",
    "\n",
    "# based on item[1] the dictionary is sorted with reverse =true which is in descending order\n",
    "\n",
    "# sorted_results.keys()-key values(class names) of sorted_result dict\n",
    "\n",
    "# sorted_results[list(sorted_results.keys())[0]] - retriving the value of the first element in the list which contains key values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c8326890",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 2s 2s/step\n",
      "Currency note:  10_new_back_up\n"
     ]
    }
   ],
   "source": [
    "def predict_image(imgname, from_test_dir):\n",
    "    test_image = tf.keras.utils.load_img(imgname, target_size = (224, 224))#image dim=224X224\n",
    "    \n",
    "    #converts input to array-returns an array\n",
    "    test_image = np.asarray(test_image)\n",
    "    \n",
    "    #axis increase number of dimensions of array-axis=0-vertically-rows\n",
    "    test_image = np.expand_dims(test_image, axis=0)\n",
    "    \n",
    "    #normalizing the values of images\n",
    "    test_image = (2.0 / 255.0) * test_image - 1.0 \n",
    "    \n",
    "    #passing the normalized image to our model for prediction\n",
    "    result = model.predict(test_image)\n",
    "    \n",
    "    #print(result)-returns an result array with probabilities of each class\n",
    "    \n",
    "    result_dict = dict() #creating a dictionary\n",
    "    \n",
    "    for key in list(final_labels.keys()):#each keys of final labels dict\n",
    "        result_dict[final_labels[key]] = result[0][key]\n",
    "    \n",
    "    #sorting dictionary based on probability values in descending order\n",
    "    sorted_results = {k: v for k, v in sorted(result_dict.items(), key=lambda item: item[1], reverse=True)} \n",
    "\n",
    "    if not from_test_dir: #if False is passed \n",
    "        for label in sorted_results.keys(): #each class name from sorted dictionary\n",
    "           \n",
    "    #printing each class name(key) and its value by multiplying value to 100 to achieve probability percentage in that format \n",
    "            print(\"{}: {}%\".format(label, sorted_results[label] * 100))\n",
    "            \n",
    "    final_result = dict() #creating a dictionary \n",
    "    \n",
    "    #creating and mapping the 1st key value pair into new dict\n",
    "    final_result[list(sorted_results.keys())[0]] = sorted_results[list(sorted_results.keys())[0]] * 100\n",
    "    return final_result\n",
    "\n",
    "#path of test image passed to predict image()\n",
    "note=predict_image('..\\\\test-images\\\\2.jpg',True)\n",
    "\n",
    "#print(note.keys())#predicted class will be in dictionary\n",
    "currency=list(note.keys())[0]#retriving that class name from dictionary\n",
    "\n",
    "print(\"Currency note: \",currency)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "151acae5",
   "metadata": {},
   "source": [
    "# VALIDATING BATCH-TEST DIRECTORY"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "908adebc",
   "metadata": {},
   "source": [
    "# true-only prints class with highest probability\n",
    "# false-prints all classes with probabilities\n",
    "# calling predict image directory and returns result to prediction parameter\n",
    "# prediction is returned in dictionary form hence we check key value in that dict with currency string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c62d0a98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 71ms/step\n",
      "100back.jpg: CORRECT PREDICTION {'100_new_back_up': 56.30040168762207}\n",
      "Predicted note:  100_new_back_up\n",
      "Orginal note: 100_new_back_up\n",
      "1/1 [==============================] - 0s 80ms/step\n",
      "100backr.jpg: CORRECT PREDICTION {'100_new_back_down': 40.80900549888611}\n",
      "Predicted note:  100_new_back_down\n",
      "Orginal note: 100_new_back_down\n",
      "1/1 [==============================] - 0s 73ms/step\n",
      "100front.jpg: CORRECT PREDICTION {'100_new_front_up': 60.642510652542114}\n",
      "Predicted note:  100_new_front_up\n",
      "Orginal note: 100_new_front_up\n",
      "1/1 [==============================] - 0s 87ms/step\n",
      "100front7.jpg: CORRECT PREDICTION {'100_new_front_up': 48.73565435409546}\n",
      "Predicted note:  100_new_front_up\n",
      "Orginal note: 100_new_front_up\n",
      "1/1 [==============================] - 0s 77ms/step\n",
      "100frontr.jpg: INCORRECT PREDICTION! {'50_new_front_down': 17.689599096775055}\n",
      "Predicted note:  50_new_front_down\n",
      "Orginal note: 100_new_front_down\n",
      "1/1 [==============================] - 0s 79ms/step\n",
      "100oldback.jpg: CORRECT PREDICTION {'100_old_back_up': 28.43058407306671}\n",
      "Predicted note:  100_old_back_up\n",
      "Orginal note: 100_old_back_up\n",
      "1/1 [==============================] - 0s 85ms/step\n",
      "100oldbackr.jpg: CORRECT PREDICTION {'100_old_back_down': 20.36127597093582}\n",
      "Predicted note:  100_old_back_down\n",
      "Orginal note: 100_old_back_down\n",
      "1/1 [==============================] - 0s 75ms/step\n",
      "100oldfront.jpg: CORRECT PREDICTION {'100_old_front_up': 22.41012156009674}\n",
      "Predicted note:  100_old_front_up\n",
      "Orginal note: 100_old_front_up\n",
      "1/1 [==============================] - 0s 79ms/step\n",
      "100oldfrontr.jpg: INCORRECT PREDICTION! {'20_old_front_down': 14.159350097179413}\n",
      "Predicted note:  20_old_front_down\n",
      "Orginal note: 100_old_front_down\n",
      "1/1 [==============================] - 0s 90ms/step\n",
      "10back.jpg: CORRECT PREDICTION {'10_new_back_up': 41.62229895591736}\n",
      "Predicted note:  10_new_back_up\n",
      "Orginal note: 10_new_back_up\n",
      "1/1 [==============================] - 0s 70ms/step\n",
      "10back1.jpg: INCORRECT PREDICTION! {'20_new_back_down': 17.23562330007553}\n",
      "Predicted note:  20_new_back_down\n",
      "Orginal note: 10_new_back_up\n",
      "1/1 [==============================] - 0s 87ms/step\n",
      "10back1r.jpg: CORRECT PREDICTION {'10_new_back_down': 28.49860191345215}\n",
      "Predicted note:  10_new_back_down\n",
      "Orginal note: 10_new_back_down\n",
      "1/1 [==============================] - 0s 85ms/step\n",
      "10backr.jpg: CORRECT PREDICTION {'10_new_back_down': 35.26108264923096}\n",
      "Predicted note:  10_new_back_down\n",
      "Orginal note: 10_new_back_down\n",
      "1/1 [==============================] - 0s 66ms/step\n",
      "10front.jpg: CORRECT PREDICTION {'10_new_front_up': 63.829147815704346}\n",
      "Predicted note:  10_new_front_up\n",
      "Orginal note: 10_new_front_up\n",
      "1/1 [==============================] - 0s 61ms/step\n",
      "10front1.jpg: CORRECT PREDICTION {'10_new_front_up': 56.27424120903015}\n",
      "Predicted note:  10_new_front_up\n",
      "Orginal note: 10_new_front_up\n",
      "1/1 [==============================] - 0s 67ms/step\n",
      "10front1r.jpg: INCORRECT PREDICTION! {'50_new_front_down': 21.1037278175354}\n",
      "Predicted note:  50_new_front_down\n",
      "Orginal note: 10_new_front_down\n",
      "1/1 [==============================] - 0s 64ms/step\n",
      "10front7.jpg: CORRECT PREDICTION {'10_new_front_up': 26.888352632522583}\n",
      "Predicted note:  10_new_front_up\n",
      "Orginal note: 10_new_front_up\n",
      "1/1 [==============================] - 0s 66ms/step\n",
      "10frontr.jpg: INCORRECT PREDICTION! {'50_new_front_down': 25.797918438911438}\n",
      "Predicted note:  50_new_front_down\n",
      "Orginal note: 10_new_front_down\n",
      "1/1 [==============================] - 0s 61ms/step\n",
      "10oldback.jpg: CORRECT PREDICTION {'10_old_back_up': 50.959330797195435}\n",
      "Predicted note:  10_old_back_up\n",
      "Orginal note: 10_old_back_up\n",
      "1/1 [==============================] - 0s 67ms/step\n",
      "10oldbackr.jpg: CORRECT PREDICTION {'10_old_back_down': 31.91123902797699}\n",
      "Predicted note:  10_old_back_down\n",
      "Orginal note: 10_old_back_down\n",
      "1/1 [==============================] - 0s 68ms/step\n",
      "10oldfront.jpg: CORRECT PREDICTION {'10_old_front_up': 23.209865391254425}\n",
      "Predicted note:  10_old_front_up\n",
      "Orginal note: 10_old_front_up\n",
      "1/1 [==============================] - 0s 67ms/step\n",
      "10oldfront7r.jpg: CORRECT PREDICTION {'10_old_front_down': 18.696270883083344}\n",
      "Predicted note:  10_old_front_down\n",
      "Orginal note: 10_old_front_down\n",
      "1/1 [==============================] - 0s 67ms/step\n",
      "10oldfrontr.jpg: INCORRECT PREDICTION! {'20_old_front_down': 21.607428789138794}\n",
      "Predicted note:  20_old_front_down\n",
      "Orginal note: 10_old_front_down\n",
      "1/1 [==============================] - 0s 64ms/step\n",
      "2000back.jpg: CORRECT PREDICTION {'2000_new_back_up': 33.34561288356781}\n",
      "Predicted note:  2000_new_back_up\n",
      "Orginal note: 2000_new_back_up\n",
      "1/1 [==============================] - 0s 66ms/step\n",
      "2000backr.jpg: CORRECT PREDICTION {'2000_new_back_down': 45.02041041851044}\n",
      "Predicted note:  2000_new_back_down\n",
      "Orginal note: 2000_new_back_down\n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "2000front.jpg: CORRECT PREDICTION {'2000_new_front_up': 46.81093692779541}\n",
      "Predicted note:  2000_new_front_up\n",
      "Orginal note: 2000_new_front_up\n",
      "1/1 [==============================] - 0s 71ms/step\n",
      "2000frontr.jpg: CORRECT PREDICTION {'2000_new_front_down': 18.638668954372406}\n",
      "Predicted note:  2000_new_front_down\n",
      "Orginal note: 2000_new_front_down\n",
      "1/1 [==============================] - 0s 65ms/step\n",
      "200back.jpg: CORRECT PREDICTION {'200_new_back_up': 60.83943843841553}\n",
      "Predicted note:  200_new_back_up\n",
      "Orginal note: 200_new_back_up\n",
      "1/1 [==============================] - 0s 64ms/step\n",
      "200back7.jpg: CORRECT PREDICTION {'200_new_back_up': 32.20495879650116}\n",
      "Predicted note:  200_new_back_up\n",
      "Orginal note: 200_new_back_up\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "200backr.jpg: CORRECT PREDICTION {'200_new_back_down': 58.31899046897888}\n",
      "Predicted note:  200_new_back_down\n",
      "Orginal note: 200_new_back_down\n",
      "1/1 [==============================] - 0s 67ms/step\n",
      "200front.jpg: CORRECT PREDICTION {'200_new_front_up': 56.02611303329468}\n",
      "Predicted note:  200_new_front_up\n",
      "Orginal note: 200_new_front_up\n",
      "1/1 [==============================] - 0s 75ms/step\n",
      "200frontr.jpg: CORRECT PREDICTION {'200_new_front_down': 24.78514313697815}\n",
      "Predicted note:  200_new_front_down\n",
      "Orginal note: 200_new_front_down\n",
      "1/1 [==============================] - 0s 77ms/step\n",
      "20back.jpg: CORRECT PREDICTION {'20_new_back_up': 41.865864396095276}\n",
      "Predicted note:  20_new_back_up\n",
      "Orginal note: 20_new_back_up\n",
      "1/1 [==============================] - 0s 64ms/step\n",
      "20backr.jpg: CORRECT PREDICTION {'20_new_back_down': 73.59334826469421}\n",
      "Predicted note:  20_new_back_down\n",
      "Orginal note: 20_new_back_down\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "20front.jpg: CORRECT PREDICTION {'20_new_front_up': 32.70508050918579}\n",
      "Predicted note:  20_new_front_up\n",
      "Orginal note: 20_new_front_up\n",
      "1/1 [==============================] - 0s 65ms/step\n",
      "20frontr.jpg: CORRECT PREDICTION {'20_new_front_down': 33.17382633686066}\n",
      "Predicted note:  20_new_front_down\n",
      "Orginal note: 20_new_front_down\n",
      "1/1 [==============================] - 0s 67ms/step\n",
      "20oldback.jpg: INCORRECT PREDICTION! {'20_old_front_up': 22.58371263742447}\n",
      "Predicted note:  20_old_front_up\n",
      "Orginal note: 20_old_back_up\n",
      "1/1 [==============================] - 0s 64ms/step\n",
      "20oldback1.jpg: INCORRECT PREDICTION! {'20_old_back_down': 18.915824592113495}\n",
      "Predicted note:  20_old_back_down\n",
      "Orginal note: 20_old_back_up\n",
      "1/1 [==============================] - 0s 66ms/step\n",
      "20oldback1r.jpg: INCORRECT PREDICTION! {'20_old_front_down': 16.963714361190796}\n",
      "Predicted note:  20_old_front_down\n",
      "Orginal note: 20_old_back_down\n",
      "1/1 [==============================] - 0s 67ms/step\n",
      "20oldbackr.jpg: INCORRECT PREDICTION! {'20_old_front_down': 17.180222272872925}\n",
      "Predicted note:  20_old_front_down\n",
      "Orginal note: 20_old_back_down\n",
      "1/1 [==============================] - 0s 70ms/step\n",
      "20oldfront.jpg: CORRECT PREDICTION {'20_old_front_up': 44.640928506851196}\n",
      "Predicted note:  20_old_front_up\n",
      "Orginal note: 20_old_front_up\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "20oldfront1.jpg: CORRECT PREDICTION {'20_old_front_up': 35.74990928173065}\n",
      "Predicted note:  20_old_front_up\n",
      "Orginal note: 20_old_front_up\n",
      "1/1 [==============================] - 0s 67ms/step\n",
      "20oldfront1r.jpg: CORRECT PREDICTION {'20_old_front_down': 24.580489099025726}\n",
      "Predicted note:  20_old_front_down\n",
      "Orginal note: 20_old_front_down\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 62ms/step\n",
      "20oldfrontr.jpg: CORRECT PREDICTION {'20_old_front_down': 44.74850594997406}\n",
      "Predicted note:  20_old_front_down\n",
      "Orginal note: 20_old_front_down\n",
      "1/1 [==============================] - 0s 68ms/step\n",
      "500back.jpg: CORRECT PREDICTION {'500_new_back_up': 84.37694907188416}\n",
      "Predicted note:  500_new_back_up\n",
      "Orginal note: 500_new_back_up\n",
      "1/1 [==============================] - 0s 64ms/step\n",
      "500back1.jpg: CORRECT PREDICTION {'500_new_back_up': 90.03133177757263}\n",
      "Predicted note:  500_new_back_up\n",
      "Orginal note: 500_new_back_up\n",
      "1/1 [==============================] - 0s 65ms/step\n",
      "500back1r.jpg: CORRECT PREDICTION {'500_new_back_down': 22.60117083787918}\n",
      "Predicted note:  500_new_back_down\n",
      "Orginal note: 500_new_back_down\n",
      "1/1 [==============================] - 0s 67ms/step\n",
      "500backr.jpg: CORRECT PREDICTION {'500_new_back_down': 34.12860631942749}\n",
      "Predicted note:  500_new_back_down\n",
      "Orginal note: 500_new_back_down\n",
      "1/1 [==============================] - 0s 64ms/step\n",
      "500front.jpg: CORRECT PREDICTION {'500_new_front_up': 39.6501362323761}\n",
      "Predicted note:  500_new_front_up\n",
      "Orginal note: 500_new_front_up\n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "500front1.jpg: CORRECT PREDICTION {'500_new_front_up': 58.968597650527954}\n",
      "Predicted note:  500_new_front_up\n",
      "Orginal note: 500_new_front_up\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "500front1r.jpg: CORRECT PREDICTION {'500_new_front_down': 38.14857304096222}\n",
      "Predicted note:  500_new_front_down\n",
      "Orginal note: 500_new_front_down\n",
      "1/1 [==============================] - 0s 59ms/step\n",
      "500frontr.jpg: CORRECT PREDICTION {'500_new_front_down': 25.64040720462799}\n",
      "Predicted note:  500_new_front_down\n",
      "Orginal note: 500_new_front_down\n",
      "1/1 [==============================] - 0s 64ms/step\n",
      "50back.jpg: CORRECT PREDICTION {'50_new_back_up': 9.212055057287216}\n",
      "Predicted note:  50_new_back_up\n",
      "Orginal note: 50_new_back_up\n",
      "1/1 [==============================] - 0s 69ms/step\n",
      "50backr.jpg: INCORRECT PREDICTION! {'50_new_front_up': 14.765693247318268}\n",
      "Predicted note:  50_new_front_up\n",
      "Orginal note: 50_new_back_down\n",
      "1/1 [==============================] - 0s 66ms/step\n",
      "50front.jpg: CORRECT PREDICTION {'50_new_front_up': 42.29054152965546}\n",
      "Predicted note:  50_new_front_up\n",
      "Orginal note: 50_new_front_up\n",
      "1/1 [==============================] - 0s 64ms/step\n",
      "50front7.jpg: CORRECT PREDICTION {'50_new_front_up': 26.77094340324402}\n",
      "Predicted note:  50_new_front_up\n",
      "Orginal note: 50_new_front_up\n",
      "1/1 [==============================] - 0s 64ms/step\n",
      "50frontr.jpg: CORRECT PREDICTION {'50_new_front_down': 50.56853890419006}\n",
      "Predicted note:  50_new_front_down\n",
      "Orginal note: 50_new_front_down\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "50oldback.jpg: CORRECT PREDICTION {'50_old_back_up': 15.344247221946716}\n",
      "Predicted note:  50_old_back_up\n",
      "Orginal note: 50_old_back_up\n",
      "1/1 [==============================] - 0s 65ms/step\n",
      "50oldbackr.jpg: CORRECT PREDICTION {'50_old_back_down': 15.014243125915527}\n",
      "Predicted note:  50_old_back_down\n",
      "Orginal note: 50_old_back_down\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "50oldfront.jpg: INCORRECT PREDICTION! {'10_old_front_up': 17.44416505098343}\n",
      "Predicted note:  10_old_front_up\n",
      "Orginal note: 50_old_front_up\n",
      "1/1 [==============================] - 0s 64ms/step\n",
      "50oldfrontr.jpg: CORRECT PREDICTION {'50_old_front_down': 24.174971878528595}\n",
      "Predicted note:  50_old_front_down\n",
      "Orginal note: 50_old_front_down\n",
      "accuracy: 80.32786885245902\n"
     ]
    }
   ],
   "source": [
    "def verify_test_dir():\n",
    "    #path of test directory\n",
    "    path = '..\\\\batch-test-images'\n",
    "    \n",
    "    #list of all files(images) in test dir will be stored in files array\n",
    "    files = os.listdir(path) \n",
    "    correct_preds = 0\n",
    "    \n",
    "    #total image count in test dir\n",
    "    file_count = len(files) \n",
    "    finals = []\n",
    "    \n",
    "    for filename in files:\n",
    "        #taking each name of file into filename parameter\n",
    "        digits = []\n",
    "        \n",
    "        for char in filename:\n",
    "            #taking each character of each file into char parameter\n",
    "            \n",
    "            #checking whether the character is digit or not\n",
    "            if char.isdigit():\n",
    "                digits += char #if digit then add to digits list\n",
    "            else:\n",
    "                break #else break\n",
    "\n",
    "        num = \"\".join(digits) #join values in digits list-[1,0,0]-100\n",
    "\n",
    "        currency_string = []\n",
    "        currency_string.append(num)#append to currency string\n",
    "        \n",
    "        #checking what type of note it is\n",
    "        if 'old' in filename:\n",
    "            currency_string.append('old')\n",
    "        else:\n",
    "            currency_string.append('new')\n",
    "\n",
    "        if 'back' in filename:\n",
    "            currency_string.append('back')\n",
    "        elif 'front' in filename:\n",
    "            currency_string.append('front')\n",
    "\n",
    "        #checking if the filename contains r(reverse allignment)-100back.jpg-[100back,jpg]\n",
    "        rev = filename.split('.')[0][-1:]\n",
    "        \n",
    "        #print(rev)-[0]means [100back]-[-1] means k\n",
    "        if rev == 'r': #k!=r\n",
    "            currency_string.append('down')\n",
    "        else:\n",
    "            currency_string.append('up') #then 100back.jpg is up\n",
    "\n",
    "        currency_string = \"_\".join(currency_string)#joining whole string with help of _\n",
    "\n",
    "        prediction = predict_image(path + '\\\\' + filename, True)\n",
    "        \n",
    "        if list(prediction.keys())[0] == currency_string: \n",
    "            #filename along with its prediction probability\n",
    "            print(\"{}: CORRECT PREDICTION\".format(filename), prediction)\n",
    "            \n",
    "            print(\"Predicted note: \",list(prediction.keys())[0])#predicted note\n",
    "            \n",
    "            print(\"Orginal note:\",currency_string)#orginal note\n",
    "            \n",
    "            correct_preds += 1 #incrementing correct prediction value\n",
    "        else:\n",
    "            print(\"{}: INCORRECT PREDICTION!\".format(filename), prediction)\n",
    "            print(\"Predicted note: \",list(prediction.keys())[0])\n",
    "            print(\"Orginal note:\", currency_string)\n",
    "            \n",
    "    acc=(correct_preds/file_count)*100 #accuracy\n",
    "    print('accuracy:',acc)\n",
    "    \n",
    "verify_test_dir()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eceb0de9",
   "metadata": {},
   "source": [
    "# COMPLETE CODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2bf5b6e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "1/1 [==============================] - 1s 668ms/step\n",
      "Currency note:  50_old_back_down\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "100back.jpg: Correct Prediction {'100_new_back_up': 50.23735761642456}\n",
      "Predicted note:  100_new_back_up\n",
      "Orginal note: 100_new_back_up\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "100backr.jpg: Correct Prediction {'100_new_back_down': 47.92151749134064}\n",
      "Predicted note:  100_new_back_down\n",
      "Orginal note: 100_new_back_down\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "100front.jpg: Correct Prediction {'100_new_front_up': 34.36532020568848}\n",
      "Predicted note:  100_new_front_up\n",
      "Orginal note: 100_new_front_up\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "100front7.jpg: Correct Prediction {'100_new_front_up': 32.50194489955902}\n",
      "Predicted note:  100_new_front_up\n",
      "Orginal note: 100_new_front_up\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "100frontr.jpg: Correct Prediction {'100_new_front_down': 29.828277230262756}\n",
      "Predicted note:  100_new_front_down\n",
      "Orginal note: 100_new_front_down\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "100oldback.jpg: Correct Prediction {'100_old_back_up': 36.883676052093506}\n",
      "Predicted note:  100_old_back_up\n",
      "Orginal note: 100_old_back_up\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "100oldbackr.jpg: Correct Prediction {'100_old_back_down': 9.882211685180664}\n",
      "Predicted note:  100_old_back_down\n",
      "Orginal note: 100_old_back_down\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "100oldfront.jpg: Correct Prediction {'100_old_front_up': 26.309344172477722}\n",
      "Predicted note:  100_old_front_up\n",
      "Orginal note: 100_old_front_up\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "100oldfrontr.jpg: Correct Prediction {'100_old_front_down': 19.845640659332275}\n",
      "Predicted note:  100_old_front_down\n",
      "Orginal note: 100_old_front_down\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "10back.jpg: Correct Prediction {'10_new_back_up': 18.771225214004517}\n",
      "Predicted note:  10_new_back_up\n",
      "Orginal note: 10_new_back_up\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "10back1.jpg: INCORRECT PREDICTION! {'10_new_back_down': 31.826767325401306}\n",
      "Predicted note:  10_new_back_down\n",
      "Orginal note: 10_new_back_up\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "10back1r.jpg: Correct Prediction {'10_new_back_down': 41.04105532169342}\n",
      "Predicted note:  10_new_back_down\n",
      "Orginal note: 10_new_back_down\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "10backr.jpg: Correct Prediction {'10_new_back_down': 59.27020311355591}\n",
      "Predicted note:  10_new_back_down\n",
      "Orginal note: 10_new_back_down\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "10front.jpg: Correct Prediction {'10_new_front_up': 67.73531436920166}\n",
      "Predicted note:  10_new_front_up\n",
      "Orginal note: 10_new_front_up\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "10front1.jpg: Correct Prediction {'10_new_front_up': 58.57769846916199}\n",
      "Predicted note:  10_new_front_up\n",
      "Orginal note: 10_new_front_up\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "10front1r.jpg: INCORRECT PREDICTION! {'10_new_front_up': 13.21023553609848}\n",
      "Predicted note:  10_new_front_up\n",
      "Orginal note: 10_new_front_down\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "10front7.jpg: Correct Prediction {'10_new_front_up': 39.817702770233154}\n",
      "Predicted note:  10_new_front_up\n",
      "Orginal note: 10_new_front_up\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "10frontr.jpg: Correct Prediction {'10_new_front_down': 46.12188637256622}\n",
      "Predicted note:  10_new_front_down\n",
      "Orginal note: 10_new_front_down\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "10oldback.jpg: Correct Prediction {'10_old_back_up': 10.56114211678505}\n",
      "Predicted note:  10_old_back_up\n",
      "Orginal note: 10_old_back_up\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "10oldbackr.jpg: Correct Prediction {'10_old_back_down': 42.36426651477814}\n",
      "Predicted note:  10_old_back_down\n",
      "Orginal note: 10_old_back_down\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "10oldfront.jpg: Correct Prediction {'10_old_front_up': 16.480082273483276}\n",
      "Predicted note:  10_old_front_up\n",
      "Orginal note: 10_old_front_up\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "10oldfront7r.jpg: Correct Prediction {'10_old_front_down': 22.894147038459778}\n",
      "Predicted note:  10_old_front_down\n",
      "Orginal note: 10_old_front_down\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "10oldfrontr.jpg: INCORRECT PREDICTION! {'50_old_front_down': 8.48725289106369}\n",
      "Predicted note:  50_old_front_down\n",
      "Orginal note: 10_old_front_down\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "2000back.jpg: Correct Prediction {'2000_new_back_up': 29.255729913711548}\n",
      "Predicted note:  2000_new_back_up\n",
      "Orginal note: 2000_new_back_up\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "2000backr.jpg: Correct Prediction {'2000_new_back_down': 43.33932399749756}\n",
      "Predicted note:  2000_new_back_down\n",
      "Orginal note: 2000_new_back_down\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "2000front.jpg: Correct Prediction {'2000_new_front_up': 69.76086497306824}\n",
      "Predicted note:  2000_new_front_up\n",
      "Orginal note: 2000_new_front_up\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "2000frontr.jpg: Correct Prediction {'2000_new_front_down': 41.40693545341492}\n",
      "Predicted note:  2000_new_front_down\n",
      "Orginal note: 2000_new_front_down\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "200back.jpg: Correct Prediction {'200_new_back_up': 46.438512206077576}\n",
      "Predicted note:  200_new_back_up\n",
      "Orginal note: 200_new_back_up\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "200back7.jpg: Correct Prediction {'200_new_back_up': 33.10766518115997}\n",
      "Predicted note:  200_new_back_up\n",
      "Orginal note: 200_new_back_up\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "200backr.jpg: Correct Prediction {'200_new_back_down': 19.347472488880157}\n",
      "Predicted note:  200_new_back_down\n",
      "Orginal note: 200_new_back_down\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "200front.jpg: Correct Prediction {'200_new_front_up': 33.090201020240784}\n",
      "Predicted note:  200_new_front_up\n",
      "Orginal note: 200_new_front_up\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "200frontr.jpg: Correct Prediction {'200_new_front_down': 25.64731240272522}\n",
      "Predicted note:  200_new_front_down\n",
      "Orginal note: 200_new_front_down\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "20back.jpg: Correct Prediction {'20_new_back_up': 16.248714923858643}\n",
      "Predicted note:  20_new_back_up\n",
      "Orginal note: 20_new_back_up\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "20backr.jpg: INCORRECT PREDICTION! {'100_new_back_up': 12.948495149612427}\n",
      "Predicted note:  100_new_back_up\n",
      "Orginal note: 20_new_back_down\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "20front.jpg: Correct Prediction {'20_new_front_up': 74.02156591415405}\n",
      "Predicted note:  20_new_front_up\n",
      "Orginal note: 20_new_front_up\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "20frontr.jpg: Correct Prediction {'20_new_front_down': 28.297099471092224}\n",
      "Predicted note:  20_new_front_down\n",
      "Orginal note: 20_new_front_down\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "20oldback.jpg: INCORRECT PREDICTION! {'20_old_front_down': 15.988534688949585}\n",
      "Predicted note:  20_old_front_down\n",
      "Orginal note: 20_old_back_up\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "20oldback1.jpg: INCORRECT PREDICTION! {'20_old_front_up': 24.220646917819977}\n",
      "Predicted note:  20_old_front_up\n",
      "Orginal note: 20_old_back_up\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "20oldback1r.jpg: Correct Prediction {'20_old_back_down': 20.02914845943451}\n",
      "Predicted note:  20_old_back_down\n",
      "Orginal note: 20_old_back_down\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "20oldbackr.jpg: INCORRECT PREDICTION! {'20_old_front_up': 19.306781888008118}\n",
      "Predicted note:  20_old_front_up\n",
      "Orginal note: 20_old_back_down\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "20oldfront.jpg: Correct Prediction {'20_old_front_up': 41.80915057659149}\n",
      "Predicted note:  20_old_front_up\n",
      "Orginal note: 20_old_front_up\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "20oldfront1.jpg: Correct Prediction {'20_old_front_up': 35.1628303527832}\n",
      "Predicted note:  20_old_front_up\n",
      "Orginal note: 20_old_front_up\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "20oldfront1r.jpg: Correct Prediction {'20_old_front_down': 10.885072499513626}\n",
      "Predicted note:  20_old_front_down\n",
      "Orginal note: 20_old_front_down\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "20oldfrontr.jpg: Correct Prediction {'20_old_front_down': 15.950576961040497}\n",
      "Predicted note:  20_old_front_down\n",
      "Orginal note: 20_old_front_down\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "500back.jpg: Correct Prediction {'500_new_back_up': 40.98888039588928}\n",
      "Predicted note:  500_new_back_up\n",
      "Orginal note: 500_new_back_up\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "500back1.jpg: Correct Prediction {'500_new_back_up': 53.136056661605835}\n",
      "Predicted note:  500_new_back_up\n",
      "Orginal note: 500_new_back_up\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "500back1r.jpg: Correct Prediction {'500_new_back_down': 48.699745535850525}\n",
      "Predicted note:  500_new_back_down\n",
      "Orginal note: 500_new_back_down\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "500backr.jpg: Correct Prediction {'500_new_back_down': 51.905858516693115}\n",
      "Predicted note:  500_new_back_down\n",
      "Orginal note: 500_new_back_down\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "500front.jpg: Correct Prediction {'500_new_front_up': 46.36250436306}\n",
      "Predicted note:  500_new_front_up\n",
      "Orginal note: 500_new_front_up\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "500front1.jpg: Correct Prediction {'500_new_front_up': 57.98717737197876}\n",
      "Predicted note:  500_new_front_up\n",
      "Orginal note: 500_new_front_up\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "500front1r.jpg: Correct Prediction {'500_new_front_down': 42.608481645584106}\n",
      "Predicted note:  500_new_front_down\n",
      "Orginal note: 500_new_front_down\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "500frontr.jpg: Correct Prediction {'500_new_front_down': 32.577332854270935}\n",
      "Predicted note:  500_new_front_down\n",
      "Orginal note: 500_new_front_down\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "50back.jpg: Correct Prediction {'50_new_back_up': 39.78269398212433}\n",
      "Predicted note:  50_new_back_up\n",
      "Orginal note: 50_new_back_up\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "50backr.jpg: Correct Prediction {'50_new_back_down': 16.88956469297409}\n",
      "Predicted note:  50_new_back_down\n",
      "Orginal note: 50_new_back_down\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "50front.jpg: Correct Prediction {'50_new_front_up': 54.08730506896973}\n",
      "Predicted note:  50_new_front_up\n",
      "Orginal note: 50_new_front_up\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "50front7.jpg: Correct Prediction {'50_new_front_up': 42.70751774311066}\n",
      "Predicted note:  50_new_front_up\n",
      "Orginal note: 50_new_front_up\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "50frontr.jpg: Correct Prediction {'50_new_front_down': 44.669896364212036}\n",
      "Predicted note:  50_new_front_down\n",
      "Orginal note: 50_new_front_down\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "50oldback.jpg: Correct Prediction {'50_old_back_up': 35.27677357196808}\n",
      "Predicted note:  50_old_back_up\n",
      "Orginal note: 50_old_back_up\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "50oldbackr.jpg: Correct Prediction {'50_old_back_down': 48.34122955799103}\n",
      "Predicted note:  50_old_back_down\n",
      "Orginal note: 50_old_back_down\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "50oldfront.jpg: Correct Prediction {'50_old_front_up': 19.90378350019455}\n",
      "Predicted note:  50_old_front_up\n",
      "Orginal note: 50_old_front_up\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "50oldfrontr.jpg: Correct Prediction {'50_old_front_down': 25.92085897922516}\n",
      "Predicted note:  50_old_front_down\n",
      "Orginal note: 50_old_front_down\n",
      "accuracy: 88.52459016393442\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.preprocessing import image\n",
    "from keras.models import load_model\n",
    "import ast, os\n",
    "\n",
    "model = load_model('currency_mobilenetmodel.h5')\n",
    "f = open(\"mobilenet_currency_class_indices.txt\", \"r\")\n",
    "labels = f.read()\n",
    "labels = ast.literal_eval(labels)\n",
    "final_labels = {v: k for k, v in labels.items()}\n",
    "\n",
    "\n",
    "def predict_image(imgname, from_test_dir):\n",
    "    test_image = tf.keras.utils.load_img(imgname, target_size = (224, 224))\n",
    "\n",
    "    # plt.imshow(test_image)\n",
    "    # plt.show()\n",
    "\n",
    "    test_image = np.asarray(test_image)\n",
    "    test_image = np.expand_dims(test_image, axis=0)\n",
    "    test_image = (2.0 / 255.0) * test_image - 1.0\n",
    "    result = model.predict(test_image)\n",
    "\n",
    "    result_dict = dict()\n",
    "    for key in list(final_labels.keys()):\n",
    "        result_dict[final_labels[key]] = result[0][key]\n",
    "    sorted_results = {k: v for k, v in sorted(result_dict.items(), key=lambda item: item[1], reverse=True)}\n",
    "\n",
    "    if not from_test_dir:\n",
    "        print('=' * 50)\n",
    "        for label in sorted_results.keys():\n",
    "            print(\"{}: {}%\".format(label, sorted_results[label] * 100))\n",
    "\n",
    "    final_result = dict()\n",
    "    final_result[list(sorted_results.keys())[0]] = sorted_results[list(sorted_results.keys())[0]] * 100\n",
    "\n",
    "    return final_result\n",
    "\n",
    "def verify_test_dir():\n",
    "    path = '..\\\\batch-test-images'\n",
    "    files = os.listdir(path)\n",
    "    correct_preds = 0\n",
    "    file_count = len(files)\n",
    "    finals = []\n",
    "    for filename in files:\n",
    "\n",
    "        digits = []\n",
    "        for al in filename:\n",
    "            if al.isdigit():\n",
    "                digits += al\n",
    "            else:\n",
    "                break\n",
    "\n",
    "        num = \"\".join(digits)\n",
    "\n",
    "        final_string = []\n",
    "        final_string.append(num)\n",
    "\n",
    "        if 'old' in filename:\n",
    "            final_string.append('old')\n",
    "        else:\n",
    "            final_string.append('new')\n",
    "\n",
    "        if 'back' in filename:\n",
    "            final_string.append('back')\n",
    "        elif 'front' in filename:\n",
    "            final_string.append('front')\n",
    "\n",
    "        rev = filename.split('.')[0][-1:]\n",
    "        if rev == 'r':\n",
    "            final_string.append('down')\n",
    "        else:\n",
    "            final_string.append('up')\n",
    "\n",
    "        final_string = \"_\".join(final_string)\n",
    "\n",
    "        prediction = predict_image(path + '\\\\' + filename, True)\n",
    "        if list(prediction.keys())[0] == final_string:\n",
    "            print(\"{}: Correct Prediction\".format(filename), prediction)\n",
    "            print(\"Predicted note: \",list(prediction.keys())[0])\n",
    "            print(\"Orginal note:\",final_string)\n",
    "            correct_preds += 1\n",
    "        else:\n",
    "            print(\"{}: INCORRECT PREDICTION!\".format(filename), prediction)\n",
    "            print(\"Predicted note: \",list(prediction.keys())[0])\n",
    "            print(\"Orginal note:\",final_string)\n",
    "    acc=(correct_preds/file_count)*100\n",
    "    print('accuracy:',acc)\n",
    "print('=' * 50)\n",
    "note=predict_image('..\\\\test-images\\\\kappa.jpg', True)\n",
    "currency=list(note.keys())[0]\n",
    "print(\"Currency note: \",currency)\n",
    "verify_test_dir()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
